import nltk
from nltk.tokenize import sent_tokenize, word_tokenize
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from nltk.tokenize import PunktSentenceTokenizer
from nltk.corpus import stopwords
import re
import string
import nltk
from nltk.collocations import BigramCollocationFinder, BigramAssocMeasures



print(open("got3.txt", "r").read().find("you know nothing"))
text = open("got3.txt", "r").read()
print(len(text))
tokenizer = PunktSentenceTokenizer()
tokenized = tokenizer.tokenize(text)
for i in tokenized:
    cnt=0
    if (i.lower().find("you know nothing")!=-1):
            cnt=cnt+1
            print(str(cnt)+": "+i)
